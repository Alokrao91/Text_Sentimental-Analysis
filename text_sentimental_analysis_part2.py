# -*- coding: utf-8 -*-
"""Text/Sentimental Analysis part2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14OS2ZI4bVhm8B5POTGXTvPyiMvSTDVwO

# Part 2
"""

import nltk
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from wordcloud import WordCloud
pd.set_option('display.max_colwidth',200)

from google.colab import drive
drive.mount('/content/drive')

# loading pickle file
tweets =pd.read_pickle('/content/drive/MyDrive/DataScience project work/cleaned_tweets_v1.pkl')
tweets.head()

tweets.shape

positive_tweets=tweets[tweets.label==1]
positive_tweets.head()

negative_tweets = tweets[tweets.label==0]
negative_tweets.head()

"""# positive tweets display without stopwords"""

positive_vocab = [token for tweet in positive_tweets.cleaned_tweets_without_stopwords for token in tweet.split()]
positive_freq = nltk.FreqDist(positive_vocab)
plt.figure(figsize=(12,5))
plt.title("Top 25 Most common Words ater removing the stopwords",fontsize=15)
plt.xticks(fontsize=15)
positive_freq.plot(50, cumulative=False)
plt.show()

negative_vocab = [token for tweet in negative_tweets.cleaned_tweets_without_stopwords for token in tweet.split()]
negative_freq = nltk.FreqDist(negative_vocab)
plt.figure(figsize=(12,5))
plt.title("Top 25 Most common Words ater removing the stopwords",fontsize=15)
plt.xticks(fontsize=15)
negative_freq.plot(50, cumulative=False)
plt.show()

positive_freq

negative_freq

positive_v1= ' '.join(map(str, positive_vocab))
pos_wordcloud = WordCloud()
pos_wordcloud.generate(positive_v1)
plt.figure(figsize=(10,8))
plt.imshow(pos_wordcloud)
plt.axis('off')
plt.show()

negative_v1= ' '.join(map(str, negative_vocab))
neg_wordcloud = WordCloud()
neg_wordcloud.generate(negative_v1)
plt.figure(figsize=(10,8))
plt.imshow(neg_wordcloud)
plt.axis('off')
plt.show()

"""# Feature Extraction - Bag of Words Model

# bow , tf-idf, ngram - basic language model
# word2vec, glove, fasttext - distributed language model
# transformers , bert, gpt -large language model(context model)
"""

tweets.head()

# spliting the dataset
x = tweets['cleaned_tweets']
y = tweets['label']

# spliting the data into training and test
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2, random_state=42,stratify=y)

from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer()
cv_train = cv.fit_transform(x_train)
cv_test = cv.transform(x_test)

cv_train

cv_train[0].todense()

cv.get_feature_names_out()

df =pd.DataFrame(cv_train.todense(),columns=cv.get_feature_names_out())
df.head(20)

df.shape

"""# Actual Machine Learning Model - Logistic Regresssion"""

from sklearn.linear_model import LogisticRegression
lr = LogisticRegression()
lr.fit(cv_train,y_train)

lr.predict(cv_train)[:20]

lr.score(cv_train,y_train)

lr.score(cv_test,y_test)

"""# TF - IDF Logistic Model"""

from sklearn.feature_extraction.text import TfidfVectorizer
TFIDF = TfidfVectorizer()
TFIDF_train = TFIDF.fit_transform(x_train)
TFIDF_test = TFIDF.transform(x_test)

lr.fit(TFIDF_train,y_train)

lr.score(TFIDF_train,y_train)

lr.score(TFIDF_test,y_test)

"""# Model Building taking account of the class imbalance - regularization method"""

Lr = LogisticRegression(class_weight = 'balanced',penalty= 'l2')
Lr.fit(TFIDF_train,y_train)

print("Train Score : ", Lr.score(TFIDF_train,y_train))

print("-----------------------------")

print("Test Score : ", Lr.score(TFIDF_test,y_test))

Lr = LogisticRegression(class_weight = 'balanced',penalty= 'l2', C=2)
Lr.fit(TFIDF_train,y_train)

print("Train Score : ", Lr.score(TFIDF_train,y_train))

print("-----------------------------")

print("Test Score : ", Lr.score(TFIDF_test,y_test))

Lr = LogisticRegression(class_weight ={0:1.5,1:0.5},penalty= 'l1', C=1, solver="liblinear",max_iter=500)
Lr.fit(TFIDF_train,y_train)

print("Train Score : ", Lr.score(TFIDF_train,y_train))

print("-----------------------------")

print("Test Score : ", Lr.score(TFIDF_test,y_test))

Lr = LogisticRegression(class_weight ='balanced',penalty= 'l1', C=2, solver="liblinear",max_iter=500)
Lr.fit(TFIDF_train,y_train)

print("Train Score : ", Lr.score(TFIDF_train,y_train))

print("-----------------------------")

print("Test Score : ", Lr.score(TFIDF_test,y_test))